# Лабораторные работы по "Фреймворкам машинного обучения"

Выполнил: Юнусов Рустам 

*Студент группы М8О-410Б-22*

## Описание

В рамках серии лабораторных работ были исследованы основные алгоритмы машинного обучения для задач **классификации** и **регрессии** на табличных данных.
Цель работ — изучить поведение различных моделей, сравнить их качество и проанализировать влияние гиперпараметров и предобработки данных.

Использовались два датасета:

* **Forest Cover Type** — задача многоклассовой классификации;
* **Car Prices** — задача регрессии (прогноз стоимости автомобиля).

Для оценки качества применялись стандартные метрики:

* классификация: *Accuracy*, *Macro-F1*;
* регрессия: *MAE*, *RMSE*.

---

## Содержание лабораторных работ

### ЛР1 — k-Nearest Neighbors (KNN)

* Реализация KNN для классификации и регрессии с использованием `scikit-learn`.
* Собственная реализация KNN на NumPy.
* Сравнение собственной реализации с `scikit-learn`.
* Анализ влияния числа соседей, весов и метрики расстояния.

### ЛР2 — Линейные модели

* Logistic Regression для классификации.
* Linear Regression и регуляризованные модели (Ridge, Lasso, ElasticNet) для регрессии.
* Исследование влияния регуляризации на качество моделей.

### ЛР3 — Decision Tree

* Decision Tree Classifier и Regressor.
* Анализ переобучения одиночных деревьев.
* Подбор гиперпараметров (глубина, размер листа).

### ЛР4 — Random Forest

* Ансамблевые модели Random Forest для классификации и регрессии.
* Сравнение с одиночными деревьями.
* Оценка влияния числа деревьев и ограничений глубины.

### ЛР5 — Gradient Boosting

* Gradient Boosting (HistGradientBoosting) для классификации и регрессии.
* Подбор гиперпараметров.
* Сравнение с Random Forest и другими моделями.

---

## Краткий вывод

В ходе лабораторных работ было показано, что:

* простые модели (линейные, одиночные деревья) имеют ограниченное качество на сложных табличных данных;
* нелинейные методы и ансамбли (KNN, Random Forest, Gradient Boosting) демонстрируют более высокое качество;
* подбор гиперпараметров не всегда приводит к улучшению результата на тестовой выборке;
* ансамблевые методы, в особенности Random Forest и Gradient Boosting, обеспечивают наилучшее соотношение устойчивости и качества.

Работы позволили на практике сравнить различные подходы машинного обучения и понять их сильные и слабые стороны.